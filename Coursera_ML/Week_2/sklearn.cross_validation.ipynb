{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Научимся делать разбиение набора данных на подвыборки. С помощью модуля **Sklearn.cross_validation** научимся делать разовые разбиения данных на обучение и тест, а также рассмотрим несколько часто встречающихся стратегий кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "документация: http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, datasets  # импортируем нужные модули\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разовое разбиение данных на обучение и тест с помощью train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris() # загрузим dataset ирисы Фишера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При решении задачи классификации нужно разбить данные на обучение и тест, чтобы впоследствии обучить модель на обучающей выборке и оценить ее качество на тесте. Для этого **cross_validation** предоставляет нам очень удобную функцию под названием **train_test_split**. Она позволяет нам построить разовое разбиение данных на обучение и тест. В качестве аргумента функция принимает набор данных, которые мы хотим разбить, набор меток классов, и также ей можно указать соотношение, в котором мы хотим разбивать данные. В данном случае отправляем 30 % объектов в тестовую выборку и все остальные — в обучающую. В результате получим 4 объекта, train_data и test_data — это части нашей выборки для обучения и для теста, непосредственное описание объектов, и train_labels и test_labels — это метки объектов из обучающей и тестовой выборки соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(iris.data, \n",
    "                                                                                    iris.target, \n",
    "                                                                                    test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#убедимся, что тестовая выборка действительно составляет 0.3 от всех данных\n",
    "float(len(test_labels))/len(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 105 объектов \n",
      "Размер тестовой выборки: 45 объектов\n"
     ]
    }
   ],
   "source": [
    "# Оценим размер train_data или test_data и также можно оценить размер train_labels или test_labels. \n",
    "# Понятно, что размеры должны получиться одинаковые. \n",
    "print('Размер обучающей выборки: {} объектов \\nРазмер тестовой выборки: {} объектов'.format(len(train_data),\n",
    "                                                                                            len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка:\n",
      " [[7.2 3.  5.8 1.6]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 4.2 1.4 0.2]] \n",
      "\n",
      "Тестовая выборка:\n",
      " [[6.4 3.1 5.5 1.8]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.  2.9 4.5 1.5]]\n"
     ]
    }
   ],
   "source": [
    "# выведем часть нашей обучающей и тестовой \n",
    "# выборки и посмотрим, как они выглядят\n",
    "print('Обучающая выборка:\\n', train_data[:5],'\\n')\n",
    "print('Тестовая выборка:\\n', test_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем полностью список лейблов на обучении и на тесте и убедиться, что, действительно, это те же самые лейблы (метки от 0 до 2), и в обучении и в тесте присутствуют объекты всех классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метки классов на обучающей выборке:\n",
      " [2 1 0 1 0 0 2 1 0 2 0 2 1 0 1 2 1 0 0 0 2 0 0 0 1 1 0 0 1 1 1 1 2 2 2 2 0\n",
      " 1 2 2 0 0 0 0 1 1 2 1 1 0 0 2 0 1 1 2 0 2 2 0 0 2 2 1 1 2 2 1 2 1 0 0 2 2\n",
      " 1 1 2 2 1 2 0 2 1 1 1 1 2 0 1 0 0 0 2 2 1 2 2 1 0 0 2 2 2 2 2] \n",
      "\n",
      "Метки классов на тестовой выборке:\n",
      " [2 2 2 1 1 0 0 0 1 0 2 2 2 2 1 1 1 0 0 2 1 1 0 2 0 0 1 2 1 2 1 0 0 1 0 1 0\n",
      " 1 1 0 1 1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Метки классов на обучающей выборке:\\n', train_labels, '\\n')\n",
    "print('Метки классов на тестовой выборке:\\n', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратегии проведения кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция **train_test_split** позволяет строить разовое разбиение на обучение и тест. Часто это полезно, если мы просто хотим оценить качество нашей модели в одной точке. Если же мы хотим получить более строгую оценку, нам нужно пользоваться **кросс-валидацией**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем короткое подобие датасета, где элементы \n",
    "# совпадают с порядковым номером\n",
    "X = range(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте начнем с простого. Первая стратегия кросс-валидации, которую мы рассмотрим, называется **KFold**. В случае **KFold** мы разбиваем нашу выборку на K групп, при этом каждая из групп 1 раз участвует в тестировании и (K − 1) раз участвует в обучении. Для того чтобы получить такую кросс-валидацию, нам нужно использовать функцию **KFold**. В качестве аргументов она принимает на вход количество объектов, которое мы хотим разбивать, и количество фолдов, которое нам нужно. В отличие от функции train_test_split, функция **KFold** не строит нам разбиение исходных данных. Она возвращает нам пару индексов: индексы из обучения и индексы из тестов, с помощью которых мы далее можем самостоятельно разбить нашу выборку.\n",
    "\n",
    "Применим эту функцию в случае, когда мы хотим разбить 10 объектов на 5 фолдов, и посмотрим, как выглядят наши индексы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7 8 9] [0 1]\n",
      "[0 1 4 5 6 7 8 9] [2 3]\n",
      "[0 1 2 3 6 7 8 9] [4 5]\n",
      "[0 1 2 3 4 5 8 9] [6 7]\n",
      "[0 1 2 3 4 5 6 7] [8 9]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits = 5)\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот мы видим наши разбиения. Каждый фолд получился размером 2 объекта, и поэтому обучающая выборка состоит каждый раз из 8 объектов, тестовая — из 2-х. Кстати, мы видим, что наши объекты разбиты по порядку. Если посмотреть на тестовую выборку, то мы видим, что каждый раз у нас индексы расположены в исходном порядке. Не всегда это удобно, в качестве примера можно вспомнить dataset ирисы Фишера, в котором объекты были исходно отсортированы по метке класса. В данном случае может получиться не очень хорошая ситуация, когда у нас в обучении или в тесте присутствуют представители не всех классов. Чтобы такого избежать, нам нужно указать параметр *shuffle* и сказать, что он должен быть равен *True*, то есть мы хотим сделать *shuffle* с нашей выборкой, хотим перемешать элементы. Вот давайте посмотрим, как будут выглядеть индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 6 8 9] [0 1 2 4 7]\n",
      "[0 1 2 4 7] [3 5 6 8 9]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits = 2, shuffle = True)\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы построили разбиение на 2 фолда, чтобы было немножечко покороче, и видим, что в данном случае объекты уже расположены не по порядку. Но при этом если мы вызовем эту функцию еще раз или еще раз, мы получаем каждый раз разные разбиения. Не всегда это удобно. Если мы хотим, чтобы результат работы нашей функции был детерминированным, то нам нужно указать параметр *random_state*, зафиксировать какое именно случайное разбиение мы будем использовать. Вот давайте его укажем и посмотрим. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 5 7 8] [0 2 4 6 9]\n",
      "[0 2 4 6 9] [1 3 5 7 8]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits = 2, shuffle = True, random_state = 1)\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили некоторое разбиение, повторные запуски этой функции приводят к таким же разбиениям. Часто это удобно, если мы хотим, чтобы результаты нашей работы были воспроизводимы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая стратегия кросс-валидации, которую мы рассмотрим, называется **StratifiedKFold**. Она очень похожа на предыдущую, но есть существенное отличие. В данном случае мы сохраняем соотношение классов в обучающих и тестовых подвыборках. Для того чтобы запустить такую функцию, нам нужно передать ей не только количество объектов, но и непосредственно метки классов на объектах, так как разбиение происходит с учетом меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1]\n",
      "[3 4 6 8 9] [0 1 2 5 7]\n",
      "[0 1 2 5 7] [3 4 6 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Создадим набор меток классов. \n",
    "# В данном случае мы создадим список из 10 элементов, \n",
    "# первые 5 элементов будут равны 0, последние 5 элементов будут равны 1. \n",
    "# Таким образом мы получили задачу бинарной классификации.\n",
    "y = np.array([0] * 5 + [1] * 5)\n",
    "print(y)\n",
    "\n",
    "# Сделаем разбиение на 2 фолда, также укажем параметр shuffle = True и random_state\n",
    "skf = model_selection.StratifiedKFold(n_splits = 2, shuffle = True, random_state = 0)\n",
    "for train_indices, test_indices in skf.split(X, y):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что метки получились такие, как мы хотели. Убедимся, что у нас соотношение объектов в обучающих и тестовых выборках также 50 на 50, как и в исходных метках. Видим, что объекты с индексом 3 и 4 имеют метку 0, объекты с индексом 8 и 9 имеют метку 1. Соответственно, соотношение правильное. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера давайте создадим другой список меток, где метки уже будут идти через одну (0 1 0 1) и посмотрим, как изменятся наши индексы. Функцию запускаем практически с такими же параметрами. Вот видим, что, да, действительно, индексы другие, и видим, что вот наш индекс 1 и 5 — это объекты с меткой 1, индексы 2 и 8 — объекты с меткой 0, то есть соотношение опять правильное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 0 1 0 1]\n",
      "[0 1 4 5 7] [2 3 6 8 9]\n",
      "[2 3 6 8 9] [0 1 4 5 7]\n"
     ]
    }
   ],
   "source": [
    "target = np.array([0, 1] * 5)\n",
    "print(target)\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits = 2,shuffle = True)\n",
    "for train_indices, test_indices in skf.split(X, target):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая интересная стратегия — это **ShuffleSplit**. Она позволяет строить так называемые случайные перестановки. Таким образом мы можем получить очень много выборок, при этом мы можем специфицировать размер обучающей выборки, и у нас нет никаких ограничений на то, сколько раз каждый объект должен появиться в обучении или в тесте. Каждый раз мы действуем с возвращением, то есть мы получаем одно разбиение и дальше можем строить другое независимо от предыдущего. В качестве аргументов функции нужно указать количество наших объектов, сколько итераций мы хотим и размер тестовой выборки. Вот давайте разобъем данные в соотношении: 80 % — обучение и 20 % — тест, и посмотрим, как будут выглядеть наши выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 6 4 5 2 1 8 9] [3 7]\n",
      "[8 0 1 5 2 7 4 3] [6 9]\n",
      "[7 8 4 1 5 3 6 2] [0 9]\n",
      "[1 3 9 7 4 8 6 5] [0 2]\n",
      "[2 8 6 9 7 4 5 0] [3 1]\n",
      "[5 7 4 3 9 8 2 6] [0 1]\n",
      "[3 4 0 5 8 7 9 2] [6 1]\n",
      "[4 9 8 7 3 6 2 1] [5 0]\n",
      "[4 9 2 6 7 0 1 5] [8 3]\n",
      "[8 3 4 2 7 1 0 6] [9 5]\n"
     ]
    }
   ],
   "source": [
    "ss = model_selection.ShuffleSplit(n_splits = 10, test_size = 0.2)\n",
    "\n",
    "for train_indices, test_indices in ss.split(X):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну вот мы построили 10 итераций. Невооруженным взглядом видно, что у нас нет никаких ограничений на то, сколько раз объект должен встретиться в обучении или в тесте. Вот, в частности, мы видим, что объект с меткой 0 сразу несколько раз попадает в тест, разбиение действительно случайное. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но **shuffle_split** также можно стратифицировать. Для этого нужно использовать функцию **StratifiedShuffleSplit**, и в этом случае мы тоже будем получать выборки, которые имеют исходное соотношение классов. Опять же, для этого нам придется передать *target* и целевую метку в функцию. И давайте посмотрим, как это выглядит. Сделаем поменьше итераций, сделаем 4 и убедимся, что все правильно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1]\n",
      "[6 7 5 2 1 4 0 8] [3 9]\n",
      "[6 4 1 2 5 7 3 8] [0 9]\n",
      "[2 5 1 0 4 7 8 6] [3 9]\n",
      "[2 4 8 7 1 9 5 3] [0 6]\n"
     ]
    }
   ],
   "source": [
    "target = np.array([0] * 5 + [1] * 5)\n",
    "print(target)\n",
    "\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits = 4, test_size = 0.2)\n",
    "for train_indices, test_indices in sss.split(X, target):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот, действительно, каждый раз мы видим, что в тесте есть один объект нулевого класса, один объект первого класса, таким образом, очевидно, что и в обучении у нас также получилась сбалансированная выборка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-One-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратегия LeaveOneOut позволяет оставить каждый объект в тесте 1 раз. Таким образом, тестовая выборка всегда состоит из одного объекта, и каждый объект из нашего набора данных 1 раз присутствует в тесте. Это очень удобная стратегия кросс-валидации, которую хорошо использовать в случае, когда мы имеем небольшую выборку данных. Давайте посмотрим, как это выглядит. Функции достаточно передать только количество объектов, и легко проверить, что мы получили правильное разбиение. Каждый объект 1 раз присутствует в тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9] [0]\n",
      "[0 2 3 4 5 6 7 8 9] [1]\n",
      "[0 1 3 4 5 6 7 8 9] [2]\n",
      "[0 1 2 4 5 6 7 8 9] [3]\n",
      "[0 1 2 3 5 6 7 8 9] [4]\n",
      "[0 1 2 3 4 6 7 8 9] [5]\n",
      "[0 1 2 3 4 5 7 8 9] [6]\n",
      "[0 1 2 3 4 5 6 8 9] [7]\n",
      "[0 1 2 3 4 5 6 7 9] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "loo = model_selection.LeaveOneOut()\n",
    "\n",
    "for train_indices, test_index in loo.split(X):\n",
    "    print(train_indices, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Больше стратегий проведения кросс-валидации доступно здесь: http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
