{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-5. Решающие деревья и случайный лес \n",
    "## Юнит 6. Основные алгоритмы машинного обучения. Часть II\n",
    "### Skillfactory: DST-10\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5.2.3\n",
    "---\n",
    "Вам предложен датасет */data/bill_authentication.csv* с некоторыми характеристиками банкнот, по которым мы будем определять, является ли банкнота фальшивой или настоящей.\n",
    "\n",
    "Более подробную информацию про датасет, а также сам датасет можно найти здесь: https://archive.ics.uci.edu/ml/datasets/banknote+authentication.\n",
    "\n",
    "Также можете его скачать напрямую по этой ссылке: https://lms.skillfactory.ru/assets/courseware/v1/ad29ebf5005123a0f5f50399a7bb64fb/asset-v1:Skillfactory+DST-10+22JAN2020+type@asset+block/bill_authentication.csv.\n",
    "\n",
    "Параметры решающего дерева, которые понадобятся для решения задачи:\n",
    "\n",
    "- max_depth — максимальная глубина дерева.\n",
    "- max_features — максимальное число признаков, по которым ищется лучшее разбиение в дереве. Это нужно потому, что при большом количестве признаков будет «дорого» искать лучшее (по критерию типа прироста информации) разбиение среди всех признаков.\n",
    "- min_samples_leaf — минимальное число объектов в листе. У этого параметра есть понятная интерпретация: если он равен 5, то дерево будет порождать только те классифицирующие правила, которые верны как минимум для 5 объектов.\n",
    "\n",
    "Обучите на данных из файла решающее дерево. Целевой переменной здесь является переменная Class. Размер тестовой выборки возьмите за 0.2, random_state = 17 для разбиения и дерева. Максимальную глубину дерева примите за 2, максимальное число признаков, по которым ищется лучшее разбиение в дереве — за 2. Какое значение f1-score вы получили? Округлите до трёх знаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED =17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>3.7321</td>\n",
       "      <td>-3.8840</td>\n",
       "      <td>3.3577</td>\n",
       "      <td>-0.006049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>3.3397</td>\n",
       "      <td>-4.6145</td>\n",
       "      <td>3.9823</td>\n",
       "      <td>-0.237510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>-1.6514</td>\n",
       "      <td>-8.4985</td>\n",
       "      <td>9.1122</td>\n",
       "      <td>1.237900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>2.7206</td>\n",
       "      <td>9.0821</td>\n",
       "      <td>-3.3111</td>\n",
       "      <td>-0.968110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>-0.0248</td>\n",
       "      <td>1.2421</td>\n",
       "      <td>-0.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variance  Skewness  Curtosis   Entropy  Class\n",
       "682    3.7321   -3.8840    3.3577 -0.006049      0\n",
       "103    3.3397   -4.6145    3.9823 -0.237510      0\n",
       "886   -1.6514   -8.4985    9.1122  1.237900      1\n",
       "356    2.7206    9.0821   -3.3111 -0.968110      0\n",
       "226    0.5706   -0.0248    1.2421 -0.562100      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Прочитаем data set\n",
    "df = pd.read_csv('./data/bill_authentication.xls', sep=',')  \n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 5 columns):\n",
      "Variance    1372 non-null float64\n",
      "Skewness    1372 non-null float64\n",
      "Curtosis    1372 non-null float64\n",
      "Entropy     1372 non-null float64\n",
      "Class       1372 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на данные \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем признаки и целевую переменную\n",
    "X = df.drop(['Class'], axis=1)\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим выборку на обучающую и тренировочную\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, \n",
    "                                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_features=2, random_state=17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель для классификации на основе дерева решений\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(max_depth=3, \n",
    "                                  max_features=2, random_state=RANDOM_SEED)\n",
    "clf_tree.fit(X_train, Y_train)   # Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.866\n"
     ]
    }
   ],
   "source": [
    "# Вычислим метрики качества\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "Y_predicted = clf_tree.predict(X_test)  # Предсказываем\n",
    "print('f1_score =', round(f1_score(Y_test, Y_predicted), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Банкнота относится к классу [0]\n"
     ]
    }
   ],
   "source": [
    "# Проклассифицируем банкноту с вектором признаков \n",
    "# [2.04378,-0.38422,1.437292,0.76421]\n",
    "# К какому классу она относится?\n",
    "class_x0 = clf_tree.predict([[2.04378, -0.38422, 1.437292, 0.76421]])\n",
    "print('Банкнота относится к классу', class_x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5.2.5\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потренируемся реализовывать задачу регрессии с помощью решающих деревьев на реальных данных. В данной задаче мы попробуем предсказать потребление топлива. Датасет лежит здесь: https://lms.skillfactory.ru/assets/courseware/v1/fc8c2fb45f3b0b86d8fe409ff0f430af/asset-v1:Skillfactory+DST-10+22JAN2020+type@asset+block/petrol_consumption.csv.\n",
    "\n",
    "Обучите решающее дерево для регрессии на предложенных данных, размер тестовой выборки возьмите за 0.3, random_state = 42 для разбиения и дерева. Вычислите RMSE, округлите до двух знаков после точки-разделителя. Какова глубина дерева?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5126</td>\n",
       "      <td>2138</td>\n",
       "      <td>0.553</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4817</td>\n",
       "      <td>6930</td>\n",
       "      <td>0.574</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4593</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.663</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3897</td>\n",
       "      <td>6385</td>\n",
       "      <td>0.586</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4983</td>\n",
       "      <td>602</td>\n",
       "      <td>0.602</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "7          8.0            5126            2138                         0.553   \n",
       "12         7.0            4817            6930                         0.574   \n",
       "20         7.0            4593            7834                         0.663   \n",
       "37         7.0            3897            6385                         0.586   \n",
       "21         8.0            4983             602                         0.602   \n",
       "\n",
       "    Petrol_Consumption  \n",
       "7                  467  \n",
       "12                 525  \n",
       "20                 649  \n",
       "37                 704  \n",
       "21                 540  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Прочитаем data set\n",
    "df = pd.read_csv('./data/petrol_consumption.xls', sep=',')  \n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48 entries, 0 to 47\n",
      "Data columns (total 5 columns):\n",
      "Petrol_tax                      48 non-null float64\n",
      "Average_income                  48 non-null int64\n",
      "Paved_Highways                  48 non-null int64\n",
      "Population_Driver_licence(%)    48 non-null float64\n",
      "Petrol_Consumption              48 non-null int64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 2.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на данные \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем признаки и целевую переменную\n",
    "X = df.drop(['Petrol_Consumption'], axis=1)\n",
    "Y = df['Petrol_Consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим выборку на обучающую и тренировочную\n",
    "RANDOM_SEED = 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, \n",
    "                                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим решающее дерево для регрессии на предложенных данных\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg_tree = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "reg_tree.fit(X_train, Y_train)   # Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 87.97\n"
     ]
    }
   ],
   "source": [
    "# Подгружаем инструмент для оценки точности модели (MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = reg_tree.predict(X_test)\n",
    "rmse = mean_squared_error(Y_test, y_pred)**0.5\n",
    "print(f'RMSE = {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина дерева = 11\n"
     ]
    }
   ],
   "source": [
    "# Определим глубину дерева\n",
    "print('Глубина дерева =', reg_tree.get_depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5.5.2. Задача о винах\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем бэггинг для деревьев решений. Для тренировки будем использовать датасет о винах. Для начала подготовим данные к классификации. Условно разделим вино на хорошее и нет. Хорошим вином будем называть вино, параметр quality которого не менее 6.\n",
    "Теперь сравним несколько методов классификации: логистическую регрессию, решающее дерево и бэггинг.\n",
    "Разбейте выборку на обучающую и тренировочную с параметрами test_size=0.30, random_state=42.\n",
    "Обучите два классификатора: логистическую регрессию (с дефолтными параметрами) и решающее дерево (random_state=42, максимальная глубина равна 10).\n",
    "\n",
    "Введите значение f1 score для классификатора, который показал наилучшее значение. Округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прочитаем data set\n",
    "df = pd.read_csv('./data/winequality-red.csv',  sep=';', quotechar=\"*\", escapechar='\"', header=0, \n",
    "                names =['fixed acidity',\"volatile acidity\",\"citric acid\",\"residual sugar\", \n",
    "                        \"chlorides\", \"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\n",
    "                        \"pH\",\"sulphates\",\"alcohol\",\"quality\"])\n",
    "\n",
    "# Хорошим вином будем называть называть вино, параметр quality которого не менее 6\n",
    "df['quality']=df['quality'].apply(lambda x: 0 if x<6 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем признаки и целевую переменную\n",
    "X = df.drop(['quality'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Разобьем выборку на обучающую и тренировочную с параметрами \n",
    "# test_size=0.30, random_state=42\n",
    "RANDOM_SEED = 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Обучим логистическую регрессию (с дефолтными параметрами)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)   # Обучаем\n",
    "y_pred_lr = lr.predict(X_test)  # Предсказываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим решающее дерево (random_state=42, максимальная глубина равна 10)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=RANDOM_SEED, max_depth=10)\n",
    "dtc.fit(X_train, y_train)   # Обучаем\n",
    "y_pred_dtc = dtc.predict(X_test)  # Предсказываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_lr = 0.753\n",
      "f1_score_dtc = 0.793\n"
     ]
    }
   ],
   "source": [
    "# Вычислим метрики качества\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "f1_dtc = f1_score(y_test, y_pred_dtc)\n",
    "print('f1_score_lr =', round(f1_lr, 3))\n",
    "print('f1_score_dtc =', round(f1_dtc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_bggc:= 0.818\n"
     ]
    }
   ],
   "source": [
    "# Обучим модель с использование бэггинга \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bggc = BaggingClassifier(base_estimator=dtc, n_estimators=1500, \n",
    "                         random_state=RANDOM_SEED)\n",
    "bggc.fit(X_train, y_train)\n",
    "y_pred_bggc = bggc.predict(X_test)\n",
    "f1_bggc = f1_score(y_test, y_pred_bggc)\n",
    "print(f\"f1_score_bggc:= {round(f1_bggc,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПРАКТИКА 5.7\n",
    "---\n",
    "\n",
    "* Загрузите датасет **digits** с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков и ответы на обучающей выборке (вам потребуются поля data и target в объекте, который возвращает load_digits).\n",
    "\n",
    "* Информацию о датасете вы можете получить, обратившись к полю DESCR у возвращаемого объекта load_digits. Нам предстоит решать задачу классификации изображений с цифрами по численным признакам.\n",
    "\n",
    "* Для оценки качества мы будем использовать cross_val_score из sklearn.model_selection с параметром  𝑐𝑣=10 . Эта функция реализует k-fold cross validation c  𝑘  равным значению параметра  𝑐𝑣 . Предлагается использовать  𝑘=10 , чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и  𝑘=5 . Функция cross_val_score будет возвращать numpy.ndarray, в котором будет  𝑘  чисел — качество в каждом из  𝑘  экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score.\n",
    "\n",
    "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадёт в диапазон, заданный для правильных ответов — в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
    "\n",
    "Чтобы ускорить вычисление cross_val_score, следует попробовать использовать параметр n_jobs. Число, которое вы подаёте в качестве этого параметра, соответствует количеству потоков вашего процессора, которое будет задействовано в вычислении. Если указать n_jobs = -1, тогда будут задействовано максимальное число потоков.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAADQCAYAAADcQn7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARhklEQVR4nO3de7BddXnG8e9DuMhNgybQlNshFhgxLRGOVEmJF9QCtSAOIFQBrRqYgiPo0IpMlTrDTFtB6WjFCRJBRRQSUFTKRaChdeSShHAzoAQDBGIS8YKWWkl4+sdaB7bhJGfnnPXb61yez8yes9dvr/XuN7c36/Z7l2wTEVHCFm0nEBHjVwpMRBSTAhMRxaTAREQxKTARUcyWbScwElOmTHFfX1/baURMeIsXL/657akbjo/pAtPX18eiRYvaTiNiwpP06GDjOUSKiGJSYCKimBSYiCgmBSYiikmBiYhiUmAiopgxfZk6Brdw9hsai/WG2xY2FismnhSYITz2qT9tJM4en7ivkTjj2XnvOaaROOd8bX4jcWLkUmBis3z+o99pJM7pF/x1I3G6sey8WxqJ86pz3txInIkkBSZigtl//g2NxLnnmL8ccp1iBUbSPODtwBrbM+qxbwL71qtMBn5le6akPmAZ8FD92e22T92c7zvwrK80kTaLP31SI3FiYjj33HNHVZzRpuQezKXA54Hn/+XbftfAe0kXAL/uWH+57ZkF8xl1Zn1uViNxfvChHzQSJ6JpxQqM7dvqPZMXkSTgOCAHtRHjWFv3wRwCrLb9k46xvSTdLWmhpEM2tqGkOZIWSVq0du3a8plGxLC1dZL3BOCKjuVVwB62n5J0IPAtSa+2/fSGG9qeC8wF6O/vzyMRYty68qqDGolz3LF3NhJnOHq+ByNpS+CdwDcHxmz/n+2n6veLgeXAPr3OLSKa1cYh0luAB22vHBiQNFXSpPr9dGBv4JEWcouIBhUrMJKuAH4I7CtppaT31x8dzx8eHgHMBu6VdA8wHzjV9i9K5RYRvVHyKtIJGxl/7yBjC4AFpXKJiHZkNnVEFJMCExHFpMBERDEpMBFRTApMRBSTAhMRxaTAREQxKTARUUwKTEQUkwITEcWkwEREMSkwEVFMydnU8yStkXR/x9i5kp6QtLR+HdHx2dmSHpb0kKSh25VHxKhXcg/mUuCwQcY/a3tm/boOQNJ+VG0cXl1v84WB/jARMXYVKzC2bwO67elyFPCNurPdT4GHgWb6BUZEa9o4B3O6pHvrQ6id6rFdgcc71llZj71Imn5HjB29LjAXAa8EZlI1+r6gHtcg6w7a0Nv2XNv9tvunTp1aJsuIaERPC4zt1bbX234OuJgXDoNWArt3rLob8GQvc4uI5vW0wEia1rF4NDBwhela4HhJ20jai6rpd3vPWoiIRpR8NvUVwBuBKZJWAp8E3ihpJtXhzwrgFADbD0i6EvgRsA44zfb6UrlFRG/0uun3JZtY/zzgvFL5RETv5U7eiCgmBSYiikmBiYhiUmAiopgUmIgoJgUmIopJgYmIYlJgIqKYFJiIKCYFJiKKSYGJiGJSYCKimF43/f60pAfrjnbXSJpcj/dJ+t+OZuBfLJVXRPROr5t+3wTMsP1nwI+Bszs+W97RDPzUgnlFRI/0tOm37Rttr6sXb6fqXBcR41Sb52D+FviPjuW9JN0taaGkQ9pKKiKaU6zh1KZIOoeqc93l9dAqYA/bT0k6EPiWpFfbfnqQbecAcwD22GOPXqUcEcPQ8z0YSScDbwfebdsA9fOQnqrfLwaWA/sMtn2eKhAxdvS66fdhwD8AR9p+pmN86sCTHCVNp2r6/Ugvc4uI5vW66ffZwDbATZIAbq+vGM0GPiVpHbAeONV2t0+FjIhRalQ0/ba9AFhQKpeIaEfu5I2IYlJgIqKYFJiIKCYFJiKKSYGJiGJSYCKimBSYiCimqwIjaVY3YxERnbrdg/lcl2MREc/b5J28kl4PHAxMlfSRjo9eCkwqmVhEjH1DTRXYGtihXm/HjvGngWNKJRUR48MmC4zthcBCSZfafrRHOUXEONHtZMdtJM0F+jq3sf3mEklFxPjQbYG5Cvgi8CWqdgpdkTSPqrnUGtsz6rGXA9+kKlYrgONs/1JV/4Z/A44AngHea3tJt98VEaNPt1eR1tm+yPadthcPvLrY7lJe/GSBjwE3294buLleBjicqtHU3lQtMS/qMreIGKW6LTDfkfR3kqZJevnAa6iNBnuyAHAUcFn9/jLgHR3jX3HldmCypGld5hcRo1C3h0gn1z/P6hgzMH0Y37mL7VUAtldJ2rke3xV4vGO9lfXYqs6N0/Q7YuzoqsDY3qt0IoAG++pBcpkLzAXo7+9/0ecRMXp0VWAknTTYuO2vDOM7V0uaVu+9TAPW1OMrgd071tsNeHIY8SNilOj2HMxrO16HAOcCRw7zO6/lhUOuk4Fvd4yfpMrrgF8PHEpFxNjU7SHShzqXJb0M+OpQ223kyQL/DFwp6f3AY8Cx9erXUV2ifpjqMvX7uvslRMRoNdynCjxDdTl5kzbyZAGAQwdZ18Bpw8wnIkahbs/BfIcXTrhOAl4FXFkqqYgYH7rdgzm/4/064FHbKwvkExHjSFcneetJjw9SzajeCfh9yaQiYnzotqPdccCdVCdkjwPukJR2DRGxSd0eIp0DvNb2GqgeVg98H5hfKrGIGPu6vQ9mi4HiUntqM7aNiAmq2z2Y6yXdAFxRL7+L6r6ViIiNGqon759QTU48S9I7gb+gmjP0Q+DyHuQXEWPYUIc5FwK/AbB9te2P2D6Tau/lwtLJRcTYNlSB6bN974aDthdRdaSLiNiooQrMSzbx2bZNJhIR489QBeYuSR/ccLCeqNhNy8yImMCGuop0BnCNpHfzQkHpp3pe0tHD+UJJ+1I1/R4wHfgEMBn4ILC2Hv+47VypihjDhnou0mrgYElvAmbUw9+zfctwv9D2Q8BMAEmTgCeAa6jaM3zW9vmb2DwixpBu+8HcCtxa4PsPBZbbfrR6aklEjCdt3417PC/cvAdwuqR7Jc2TtNNgG0iaI2mRpEVr164dbJWIGCVaKzCStqZqu3lVPXQR8Eqqw6dVwAWDbWd7ru1+2/1Tp07tSa4RMTxt7sEcDiypz/Nge7Xt9bafAy4GDmoxt4hoQJsF5gQ6Do82eMja0cD9Pc8oIho13J68IyJpO+CtwCkdw/8qaSZVa84VG3wWEWNQKwXG9jPAKzYYO7GNXCKinLavIkXEOJYCExHFpMBERDEpMBFRTApMRBSTAhMRxaTAREQxKTARUUwKTEQUkwITEcWkwEREMSkwEVFMK5MdASStoHqo23pgne1+SS+nagjeRzWj+jjbv2wrx4gYmbb3YN5ke6bt/nr5Y8DNtvcGbq6XI2KMarvAbOgo4LL6/WXAO1rMJSJGqM0CY+BGSYslzanHdrG9CqD+ufOGG6Xpd8TY0do5GGCW7Scl7QzcJOnBbjayPReYC9Df3++SCUbEyLS2B2P7yfrnGqoHrx0ErB7ozVv/XNNWfhExcq0UGEnbS9px4D3wNqom39cCJ9ernQx8u438IqIZbR0i7UL1zOuBHL5u+3pJdwFXSno/8BhwbEv5RUQD2mr6/Qiw/yDjT1E9TjYixoHRdpk6IsaRFJiIKCYFJiKKSYGJiGJSYCKimBSYiCgmBSYiikmBiYhiUmAiopgUmIgoJgUmIopJgYmIYnpeYCTtLulWScskPSDpw/X4uZKekLS0fh3R69wiolltzKZeB3zU9pK6J8xiSTfVn33W9vkt5BQRBfS8wNS9dgf67v5G0jJg117nERHltXoORlIf8BrgjnrodEn3SponaafWEouIRrRWYCTtACwAzrD9NHAR8EpgJtUezgUb2S5PFYgYI9rqybsVVXG53PbVALZX215v+zngYqom4C9ie67tftv9U6dO7V3SEbHZ2riKJOASYJntz3SMT+tY7WiqJuARMYa1cRVpFnAicJ+kpfXYx4ETJM2keiDbCuCUFnKLiAa1cRXpvwEN8tF1vc4lIsrKnbwRUUwKTEQUkwITEcWkwEREMSkwEVFMCkxEFJMCExHFpMBERDEpMBFRTApMRBSTAhMRxaTAREQxKTARUcyoKzCSDpP0kKSHJX2s7XwiYvhGVYGRNAn4d+BwYD+qHjH7tZtVRAzXqCowVG0yH7b9iO3fA98Ajmo5p4gYJtluO4fnSToGOMz2B+rlE4E/t316xzpzgDn14r7AQ5vxFVOAnzeUbi/ijtXYyXnsx97cuHvaflGT7DZaZm7KYJ3u/qAC2p4LzB1WcGmR7f7hbNtG3LEaOzmP/dhNxR1th0grgd07lncDnmwpl4gYodFWYO4C9pa0l6StgeOBa1vOKSKGaVQdItleJ+l04AZgEjDP9gMNfsWwDq1ajDtWYyfnsR+7kbij6iRvRIwvo+0QKSLGkRSYiChmQhSYUtMPJM2TtEZSo4+5lbS7pFslLZP0gKQPNxj7JZLulHRPHfufmopdx58k6W5J32047gpJ90laKmlRw7EnS5ov6cH69/z1DcXdt8534PW0pDMain1m/ed3v6QrJL2kibh17A/XcR8Ycb62x/WL6mTxcmA6sDVwD7BfQ7FnAwcA9zec8zTggPr9jsCPG8xZwA71+62AO4DXNZj7R4CvA99t+PdkBTCl0N+Ry4AP1O+3BiYX+I5JwM+obkgbaaxdgZ8C29bLVwLvbSjPGVTPhd+O6iLQ94G9hxtvIuzBFJt+YPs24BdNxNog7irbS+r3vwGWUf2laiK2bf+2XtyqfjVypl/SbsBfAV9qIl4vSHop1X8UlwDY/r3tXxX4qkOB5bYfbSjelsC2krakKgZN3S/2KuB228/YXgcsBI4ebrCJUGB2BR7vWF5JQ/9Ye0FSH/Aaqj2NpmJOkrQUWAPcZLup2BcCfw8811C8TgZulLS4ni7SlOnAWuDL9aHdlyRt32D8AccDVzQRyPYTwPnAY8Aq4Ne2b2wiNtXey2xJr5C0HXAEf3jz62aZCAVmyOkHo5WkHYAFwBm2n24qru31tmdS3Sl9kKQZI40p6e3AGtuLR5zg4GbZPoBqpv1pkmY3FHdLqsPci2y/BvgfoNE2IfVNo0cCVzUUbyeqvfC9gD8Gtpf0niZi214G/AtwE3A91SmFdcONNxEKzJicfiBpK6ricrntq0t8R30o8J/AYQ2EmwUcKWkF1WHomyV9rYG4ANh+sv65BriG6tC3CSuBlR17cfOpCk6TDgeW2F7dULy3AD+1vdb2s8DVwMENxcb2JbYPsD2b6hTAT4YbayIUmDE3/UCSqM4JLLP9mYZjT5U0uX6/LdVf1gdHGtf22bZ3s91H9Xt8i+1G/leVtL2kHQfeA2+j2pUfMds/Ax6XtG89dCjwoyZidziBhg6Pao8Br5O0Xf135VCq83SNkLRz/XMP4J2MIPdRNVWgBBecfiDpCuCNwBRJK4FP2r6kgdCzgBOB++pzJQAft31dA7GnAZfVzb22AK603egl5QJ2Aa6p/i2xJfB129c3GP9DwOX1f0CPAO9rKnB9HuOtwClNxbR9h6T5wBKqw5e7aXbKwAJJrwCeBU6z/cvhBspUgYgoZiIcIkVES1JgIqKYFJiIKCYFJiKKSYGJiGJSYKJxkv5I0jckLZf0I0nXSdqn6VnnMfqN+/tgorfqG7+uAS6zfXw9NpPqXpaYYLIHE017E/Cs7S8ODNheSseEU0l9kv5L0pL6dXA9Pk3SbXXvlPslHVJPzLy0Xr5P0pm9/yXFcGUPJpo2AxhqwuMa4K22fydpb6pb0fuBvwFusH1efafxdsBMYFfbM6BqDlUu9WhaCky0YSvg8/Wh03pgn3r8LmBePdHzW7aXSnoEmC7pc8D3gKbaEkQP5BApmvYAcOAQ65wJrAb2p9pz2Rqeb+A1G3gC+Kqkk+p5MPtTzfo+jTHUzCpSYKJ5twDbSPrgwICk1wJ7dqzzMmCV7eeoJnVOqtfbk6qnzMVUs8kPkDQF2ML2AuAfab6VQhSUQ6RolG1LOhq4UFWD9d9R9dPtbB79BaoZu8cCt1I1eYJqZvpZkp4FfgucRNV98MuSBv4zPLv4LyIak9nUEVFMDpEiopgUmIgoJgUmIopJgYmIYlJgIqKYFJiIKCYFJiKK+X84+BfqjRL97wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Посмотрим на распределение объектов по классам\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(digits.target)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем зависимую и независимую переменные\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.7.1\n",
    "1. Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score. Эту величину введите в поле для ответа (ваше значение должно попасть в заданный интервал)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество в каждом разбиении:  [0.77222222 0.85555556 0.81111111 0.78333333 0.78888889 0.88888889\n",
      " 0.89444444 0.81564246 0.82681564 0.83240223]\n",
      "Среднее по кросс-валидации:  0.8269304779639975\n"
     ]
    }
   ],
   "source": [
    "# Обучим решающее дерево для классификации на предложенных данных\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score = cross_val_score(dtc, X, y, cv=10, n_jobs=-1)\n",
    "print('Качество в каждом разбиении: ', cv_score)\n",
    "print('Среднее по кросс-валидации: ', cv_score.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Теперь давайте обучим BaggingClassifier на основе DecisionTreeClassifier. Из sklearn.ensemble импортируйте BaggingClassifier, все параметры задайте по умолчанию. Нужно изменить только количество базовых моделей, задав его равным 100.\n",
    "\n",
    "В поле для ответа введите качество бэггинга на нашем датасете (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "Подумайте, какие выводы можно сделать из соотношения качества одиночного дерева и бэггинга деревьев?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество в каждом разбиении:  [0.86111111 0.96666667 0.91111111 0.92222222 0.92777778 0.98333333\n",
      " 0.96111111 0.91620112 0.86592179 0.91620112]\n",
      "Среднее по кросс-валидации:  0.9231657355679701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bggc = BaggingClassifier(base_estimator=dtc, n_estimators=100)\n",
    "\n",
    "cv_score = cross_val_score(bggc, X, y, cv=10, n_jobs=-1)\n",
    "print('Качество в каждом разбиении: ', cv_score)\n",
    "print('Среднее по кросс-валидации: ', cv_score.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех  $d$ признаках, а на $\\sqrt{d}$  случайных признаках.\n",
    "В поле для ответа введите качество работы получившегося классификатора (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "Корень из числа признаков — часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три, $\\log{d}$ тоже имеет место быть. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков, добиваясь лучшего качества на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество в каждом разбиении:  [0.9        0.96666667 0.93888889 0.89444444 0.96111111 0.92777778\n",
      " 0.96666667 0.96648045 0.90502793 0.92178771]\n",
      "Среднее по кросс-валидации:  0.934885164494103\n"
     ]
    }
   ],
   "source": [
    "bggc_sqrt_features = BaggingClassifier(dtc, n_estimators=100, \n",
    "                                       max_features=int((X.shape[1])**0.5))\n",
    "cv_score = cross_val_score(bggc_sqrt_features, X, y, cv=10, n_jobs=-1)\n",
    "print('Качество в каждом разбиении: ', cv_score)\n",
    "print('Среднее по кросс-валидации: ', cv_score.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. В предыдущем пункте мы выбирали подмножество один раз для каждого очередного дерева. Следующим нашим шагом будет построение бэггинга на основе деревьев, которые выбирают случайное подможество признаков для каждой вершины дерева.\n",
    "\n",
    "Для этого нам потребуется перенести отвечающий за это параметр из BaggingClassifier в DecisionTreeClassifier. Для этого вам из документации нужно выяснить, какой параметр DecisionTreeClassifier за это отвечает.\n",
    "\n",
    "В поле для ответа введите значение этого параметра (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "По-прежнему сэмплируем $sqrt(d)$ признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество в каждом разбиении:  [0.91666667 0.97222222 0.93888889 0.93888889 0.96111111 0.96666667\n",
      " 0.98333333 0.98882682 0.94972067 0.93854749]\n",
      "Среднее по кросс-валидации:  0.9554872749844817\n"
     ]
    }
   ],
   "source": [
    "random_dtc = DecisionTreeClassifier(splitter='random', \n",
    "                                    max_features=int((X.shape[1])**0.5))\n",
    "random_bggc = BaggingClassifier(base_estimator=random_dtc, n_estimators=100)\n",
    "cv_score = cross_val_score(random_bggc, X, y, cv=10, n_jobs=-1)\n",
    "print('Качество в каждом разбиении: ', cv_score)\n",
    "print('Среднее по кросс-валидации: ', cv_score.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный в задании 4 классификатор — бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble?\n",
    "\n",
    "Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева.\n",
    "\n",
    "Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744017807456873"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(oob_score=True)\n",
    "rfc.fit(X, y)\n",
    "rfc.oob_score_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_depth = []\n",
    "mean_score = []\n",
    "for i in range(1,30):\n",
    "    random_forest = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_features=int((X.shape[1])**0.5),\n",
    "        max_depth=i,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_forest.fit(X, y)\n",
    "    random_forest.oob_score_.mean()\n",
    "    \n",
    "    count_depth.append(i)\n",
    "    mean_score.append(random_forest.oob_score_.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Качество модели')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "axes = fig.add_axes([0,0,1,1])\n",
    "axes.plot(count_depth, mean_score, 'mD')\n",
    "plt.xlabel('Глубина дерева')\n",
    "plt.ylabel('Качество модели')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
